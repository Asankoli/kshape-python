{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import rand_score, normalized_mutual_info_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c73375",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e74dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataLoader:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.path = dataset_path\n",
    "\n",
    "    def load(self, sub_dataset_name):\n",
    "        ts, labels = [], []\n",
    "        for mode in ['_TRAIN', '_TEST']:\n",
    "            with open(os.path.join(self.path, sub_dataset_name, sub_dataset_name + mode)) as csv_file:\n",
    "                lines = csv.reader(csv_file, delimiter=',')\n",
    "                for line in lines:\n",
    "                    ts.append([float(x) for x in line[1:]])\n",
    "                    labels.append(int(line[0])-1)\n",
    "\n",
    "        if min(labels) == 1:\n",
    "            labels = labels - 1\n",
    "        if min(labels) == -1:\n",
    "            labels = labels + 1\n",
    "\n",
    "        return np.array(ts), np.array(labels), int(len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5914e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/univariate_example/'\n",
    "DATASET_NAME = 'Crop'\n",
    "\n",
    "dataloder = ClusterDataLoader(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4f7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, labels, num_clusters = dataloder.load(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b526e93",
   "metadata": {},
   "source": [
    "# CPU Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d5b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kshape.core import kshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33244d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = []\n",
    "for i in range(5):\n",
    "    start_time = time.time()\n",
    "    cpu_kshape_model = kshape(np.expand_dims(ts, axis=2), num_clusters)\n",
    "    cpu_times.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a3bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CPU Benchmark for 5 Runs: 2527.477051258087\n"
     ]
    }
   ],
   "source": [
    "print('Mean CPU Benchmark for 5 Runs:', np.mean(cpu_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9d19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(ts.shape[0])\n",
    "for i in range(num_clusters):\n",
    "    predictions[cpu_kshape_model[i][1]] = i\n",
    "\n",
    "cluster_centers = np.zeros((num_clusters, ts.shape[1], 1))\n",
    "for k in range(num_clusters):\n",
    "    cluster_centers[k, :, :] = cpu_kshape_model[k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2101fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Score: 0.9241423149575677\n",
      "Adjusted Rand Score: 0.2446950839815576\n",
      "Normalized Mutual Information: 0.4313775426755777\n"
     ]
    }
   ],
   "source": [
    "ri_ks = rand_score(predictions, labels)\n",
    "print('Rand Score:', ri_ks)\n",
    "ari_ks = adjusted_rand_score(predictions, labels)\n",
    "print('Adjusted Rand Score:', ari_ks)\n",
    "nmi_ks = normalized_mutual_info_score(predictions, labels)\n",
    "print('Normalized Mutual Information:', nmi_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522b394",
   "metadata": {},
   "source": [
    "# GPU Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653448fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kshape.core_gpu import kshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1634a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_times = []\n",
    "for i in range(5):\n",
    "    start_time = time.time()\n",
    "    gpu_kshape_model = kshape(np.expand_dims(ts, axis=2), num_clusters)\n",
    "    gpu_times.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f0b6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean GPU Benchmark for 5 Runs: 33078.67823410034\n"
     ]
    }
   ],
   "source": [
    "print('Mean GPU Benchmark for 5 Runs:', np.mean(gpu_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6af5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(ts.shape[0])\n",
    "for i in range(num_clusters):\n",
    "    predictions[gpu_kshape_model[i][1]] = i\n",
    "\n",
    "cluster_centers = np.zeros((num_clusters, ts.shape[1], 1))\n",
    "for k in range(num_clusters):\n",
    "    cluster_centers[k, :, :] = gpu_kshape_model[k][0].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c4ec37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Score: 0.9350468352848035\n",
      "Adjusted Rand Score: 0.24933303905728887\n",
      "Normalized Mutual Information: 0.4350312365117842\n"
     ]
    }
   ],
   "source": [
    "ri_ks = rand_score(predictions, labels)\n",
    "print('Rand Score:', ri_ks)\n",
    "ari_ks = adjusted_rand_score(predictions, labels)\n",
    "print('Adjusted Rand Score:', ari_ks)\n",
    "nmi_ks = normalized_mutual_info_score(predictions, labels)\n",
    "print('Normalized Mutual Information:', nmi_ks)                                                                                                                                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
